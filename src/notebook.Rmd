---
title: "We're wasting money by only supporting gzip for raw DNA sequence."
---

```{r, load-data, echo=FALSE, message=FALSE, fig.height=4}
library('ggplot2')

theme_set(theme_bw())

# Knitr automatically assumes the current working directory is where the file is.
data <- read.csv('../out/benchmark.SRR7589561.csv', header=TRUE)
```

The cheaper and greater throughput of Illumina DNA sequencing means
institutions and companies are paying monthly storage costs for terabytes of
raw DNA sequence (FASTQ). This data is stored using gzip, a 30 year old
compression algorithm. Bioinformatics tools should support more recent
algorithms such as zstd for FASTQ data. Zstd has wide industry support, with
comparable run times and would likely reduce storage costs by 50% over gzip.

## Gzip is outperformed by other algorithms

The original Gailly/Madler implementation has been surpassed in performance by
other gzip implementations. For example [cloudflare-zlib][] outperforms Madler
gzip in compression speeds and should be used instead of the default system
gzip.

[cloudflare-zlib]: https://github.com/cloudflare/zlib

The gzip compression format is still ubiquitous for raw FASTQ DNA sequence.
This is due to it being the only supported compression format for
bioinformatics tools. In the thirty years since gzip was created there are now
alternatives with superior compression ratios. Only supporting gzip for FASTQ
translates into millions of dollars in storage fees on services like Amazon's
S3 and EFS compared with algorithms with better compression ratios. Companies
like [Meta][meta], [Amazon][amzn], and [Twitter][twtr] are all reportedly using
zstd format for storing data. If the most common bioinformatics tools can move
to support ingesting zstd-compressed FASTQ format this could save everyone time
and money with minimal impact on compression times.

[meta]: https://engineering.fb.com/2016/08/31/core-data/smaller-and-faster-data-compression-with-zstandard/
[amzn]: https://twitter.com/adrianco/status/1560854827810361345
[twtr]: https://twitter.com/danluu/status/1560831128914649088

## A toy benchmark

As an example a zstd compressed FASTQ file ([SRR7589561][]) is almost 50% the
size of the same gzipped file. In the figure below I downloaded ~1.5Gb of FASTQ
data and compressed with either `pigz` or `zstd`.

[SRR7589561]: https://trace.ncbi.nlm.nih.gov/Traces/?view=run_browser&acc=SRR7589561&display=metadata

```{r, file-size-example, results='asis', echo=FALSE, message=FALSE, fig.height=5, fig.cap="FASTQ file size by compression"}
original_file_size <- 1452
file_size <- data.frame(
  name = factor(c("original", "pigz -9", "zstd -15")),
  size_mb = c(original_file_size, 238, 134)
)

ggplot(data=file_size, aes(x=name, y=size_mb)) +
    geom_bar(stat = "identity") +
    scale_x_discrete("") +
    scale_y_continuous("File size (MB)")
```

FASTQ files do however take longer to compress with zstd. The `ztsd -15`
command takes ~70s which is 50% longer than `pigz -9` at ~35s. However, it's
worth noting for storing raw data from a sequencer, these files are compressed
once, then stored for years. This additional CPU time cost is more than offset
by savings in storage costs. The same does not apply for intermediate files
such trimmed or filtered FASTQ in a pipeline that tend to be ephemeral. These
should likely continue to use gzip.

```{r, compress-time-example, results='asis', echo=FALSE, message=FALSE, fig.height=5, fig.cap="File compression time"}
compress_time <- data.frame(
  name = factor(c("pigz -9", "zstd -15")),
  compress_time = c(37.28, 73.03),
  decompress_time = c(2.22, 3.52)
)

ggplot(data=compress_time, aes(x=name, y=compress_time)) +
    geom_bar(stat = "identity") +
    scale_x_discrete("") +
    scale_y_continuous("Compression time in seconds")
```

Changes in decompression time are relatively small, 3.5s vs 2.2s. Therefore
decompression would be minimally impacted.

```{r, decompress-time-example, results='asis', echo=FALSE, message=FALSE, fig.height=5, fig.cap="File decompression time"}
ggplot(data=compress_time, aes(x=name, y=decompress_time)) +
    geom_bar(stat = "identity") +
    scale_x_discrete("") +
    scale_y_continuous("Decompression time in seconds")
```

## Detail comparison of flags

This figure compares the compressed output file size for all the different
available gzip implementations with zstd for different compression flags on the
same SRR7589561 FASTQ file. This shows that zstd outperforms gzip at the
highest compression levels, with the output file sizes being ~60% the size of
the highest gzip compression levels.

```{r, plot-file-size, results='asis', echo=FALSE, message=FALSE, fig.height=5}
ggplot(data=data, aes(x=compression_level, y=compression_ratio, color=method)) +
    geom_ribbon(stat='smooth', method = "loess", se=TRUE, alpha=0.075, linetype=0, aes(color = NULL, group = factor(method))) +
    geom_line(stat="smooth",method = "loess", alpha = 0.5) +
    geom_point() +
    scale_x_continuous("Given compression flag") +
    scale_y_continuous("Ratio of compressed size to original size")
```

This next plot compares the trade offs for file size versus the wall clock run
time taken to compress a FASTQ file. This is for the compression process running
single threaded. This shows that zstd can result in much better compression
ratios, ~10% of the original file size but with increasing run time. Though not
nearly as long as the run time for zopfli, a gzip implementation that gives the
best compression ratio of any gzip implementation but at the expense ~2 orders
of magnitude in compression time.

```{r, plot-compression-time, results='asis', echo=FALSE, message=FALSE, fig.height=5}
ggplot(data=data, aes(y=compress_time, x=compression_ratio, color=method)) +
    geom_ribbon(stat='smooth', method = "loess", se=TRUE, alpha=0.075, linetype=0, aes(color = NULL, group = factor(method))) +
    geom_line(stat="smooth",method = "loess", alpha = 0.5) +
    geom_point() +
    scale_x_log10("Ratio of compressed size to original size") +
    scale_y_log10("Compression time in seconds (single threaded)")
```

# Takeaway

The gzip implementation is superseded by other compression algorithms such as
zstd. By continuing to only support gzip for FASTQ, the bioinformatics industry spends
money unnecessarily on additional storage. Bioinformatics tools should widely
support zstd as a compression format for FASTQ.

